@misc{wiktionary,
  title   = {Wiktionary},
  url     = {https://www.wiktionary.org/},
  urldate = {2021-09-24}
}

@inproceedings{wu_computational_2020,
  title     = {Computational Etymology and Word Emergence},
  author    = {Wu,
  Winston  and
      Yarowsky, David},
  booktitle = {Proceedings of the 12th Language Resources and Evaluation
  Conference},
  month     = may,
  year      = {2020},
  address   = {Marseille,
  France},
  publisher = {European Language Resources Association},
  url       = {https://aclanthology.org/2020.lrec-1.397},
  pages     = {3252--3259},
  abstract  = {We developed an extensible, comprehensive Wiktionary parser that improves
  over several existing parsers. We predict the etymology of a word across the
  full range of etymology types and languages in Wiktionary, showing
  improvements over a strong baseline. We also model word emergence and show the
  application of etymology in modeling this phenomenon. We release our parser to
  further research in this understudied field.},
  language  = {English},
  isbn      = {979-10-95546-34-4}
}

@article{alshaabi_augmenting_2021,
  title    = {Augmenting semantic lexicons using word embeddings and transfer
  learning},
  url      = {http://arxiv.org/abs/2109.09010},
  abstract = {Sentiment-aware intelligent systems are essential to a wide array of
  applications including marketing, political campaigns, recommender systems,
  behavioral economics, social psychology, and national security. These
  sentiment-aware intelligent systems are driven by language models which
  broadly fall into two paradigms: 1. Lexicon-based and 2. Contextual. Although
  recent contextual models are increasingly dominant, we still see demand for
  lexicon-based models because of their interpretability and ease of use. For
  example, lexicon-based models allow researchers to readily determine which
  words and phrases contribute most to a change in measured sentiment. A
  challenge for any lexicon-based approach is that the lexicon needs to be
  routinely expanded with new words and expressions. Crowdsourcing annotations
  for semantic dictionaries may be an expensive and time-consuming task. Here,
  we propose two models for predicting sentiment scores to augment semantic
  lexicons at a relatively low cost using word embeddings and transfer learning.
  Our first model establishes a baseline employing a simple and shallow neural
  network initialized with pre-trained word embeddings using a non-contextual
  approach. Our second model improves upon our baseline, featuring a deep
  Transformer-based network that brings to bear word definitions to estimate
  their lexical polarity. Our evaluation shows that both models are able to
  score new words with a similar accuracy to reviewers from Amazon Mechanical
  Turk, but at a fraction of the cost.},
  urldate  = {2021-09-24},
  journal  = {arXiv:2109.09010 [physics]},
  author   = {Alshaabi, Thayer and Van Oort, Colin
  and Fudolig, Mikaela and Arnold, Michael V. and Danforth, Christopher M. and
  Dodds, Peter Sheridan},
  month    = sep,
  year     = {2021},
  note     = {arXiv:
  2109.09010},
  keywords = {Computer Science - Computation and Language, Computer
  Science - Machine Learning, Computer Science - Social and Information
  Networks, Physics - Physics and Society}
}

@article{peters_deep_2018,
  title    = {Deep contextualized word representations},
  url      = {http://arxiv.org/abs/1802.05365},
  abstract = {We introduce a new type of deep
  contextualized word representation that models both (1) complex
  characteristics of word use (e.g., syntax and semantics), and (2) how these
  uses vary across linguistic contexts (i.e., to model polysemy). Our word
  vectors are learned functions of the internal states of a deep bidirectional
  language model (biLM), which is pre-trained on a large text corpus. We show
  that these representations can be easily added to existing models and
  significantly improve the state of the art across six challenging NLP
  problems, including question answering, textual entailment and sentiment
  analysis. We also present an analysis showing that exposing the deep internals
  of the pre-trained network is crucial, allowing downstream models to mix
  different types of semi-supervision signals.},
  urldate  = {2021-09-24},
  journal  = {arXiv:1802.05365 [cs]},
  author   = {Peters, Matthew E. and
  Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and
  Lee, Kenton and Zettlemoyer, Luke},
  month    = mar,
  year     = {2018},
  note     = {arXiv: 1802.05365},
  keywords = {Computer Science - Computation and
  Language}
}

